{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# unicode NLP\n",
    "NLP模型经常处理不同的语言，不同的语言又有不同的词典\n",
    "Unicode是针对于几乎所有语言都可以用其进行表示文字的方法\n",
    "unicode character是0-0x0FFFF的int值\n",
    "unicode string是一串0或者unicode character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "tf.get_logger().setLevel('ERROR')\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1' # 使用 GPU 1\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0],True)\n",
    "logical_devices = tf.config.list_logical_devices(\"GPU\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## tf.string data type"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(), dtype=string, numpy=b'Thanks \\xce\\xb8_\\xce\\xb8!'>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 基本的tf.string类型允许byte strings 即b''\n",
    "# 默认unicode string是通过utf-8进行编码\n",
    "tf.constant(u\"Thanks θ_θ!\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2,), dtype=string, numpy=array([b\"You're\", b'welcome!'], dtype=object)>"
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tf.string将byte strings看做一个原字体 这样tf.string的长度是可变的 所以tf.string的多维表示的shape最后一维是没有意义的\n",
    "tf.constant([u\"You're\", u\"welcome!\"]).shape\n",
    "# shape 2表示有2个tf.string对象 第二维不表示"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 原生unicode的表示\n",
    "tensorflow中unicode的表示有两种\n",
    "1. string scalar string类型的标量 这样表示为一个string内部用\\分割的各个character的表示\n",
    "2. int32 vector int类型的向量 这样就将每个character表征为int 生成向量表示"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(), dtype=string, numpy=b'\\xe8\\x87\\xaa\\xe7\\x84\\xb6\\xe8\\xaf\\xad\\xe8\\xa8\\x80\\xe5\\xa4\\x84\\xe7\\x90\\x86'>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 默认是使用utf-8进行表示 这是因为string默认编码为utf-8\n",
    "text_utf8 = tf.constant(\"自然语言处理\")\n",
    "text_utf8"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(), dtype=string, numpy=b'\\x81\\xeaq6\\x8b\\xed\\x8a\\x00Y\\x04t\\x06'>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将string转为utf-16-be类型 对应的tf表示也会变化\n",
    "text_utf16be = tf.constant(u\"自然语言处理\".encode(\"UTF-16-BE\"))\n",
    "text_utf16be"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(6,), dtype=int32, numpy=array([33258, 28982, 35821, 35328, 22788, 29702], dtype=int32)>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 这样通过ord方法就可以获得int值 作为向量进行表示\n",
    "text_chars = tf.constant([ord(s) for s in u\"自然语言处理\"])\n",
    "text_chars"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## tf.strings方法进行表示unicode\n",
    "1. tf.strings.unicode_decode:将string scalar转为code points的向量\n",
    "2. tf.strings.unicode_encode:将code points向量转为 string scalar\n",
    "3. tf.strings.unicode_transcode:将string scalar转为其他形式的编码 如utf-8 -> utf-16-be"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(6,), dtype=int32, numpy=array([33258, 28982, 35821, 35328, 22788, 29702], dtype=int32)>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_decode(text_utf8, input_encoding='UTF-8')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(), dtype=string, numpy=b'\\xe8\\x87\\xaa\\xe7\\x84\\xb6\\xe8\\xaf\\xad\\xe8\\xa8\\x80\\xe5\\xa4\\x84\\xe7\\x90\\x86'>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_encode(text_chars, output_encoding='UTF-8')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(), dtype=string, numpy=b'\\xe8\\x87\\xaa\\xe7\\x84\\xb6\\xe8\\xaf\\xad\\xe8\\xa8\\x80\\xe5\\xa4\\x84\\xe7\\x90\\x86'>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_transcode(text_utf16be, input_encoding='UTF-16-BE', output_encoding='UTF-8')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## tf.strings方法对带有batch的内容处理\n",
    "对于不同长度的string进行处理 生成的是tf.RaggedTensor"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "[b'h\\xc3\\x83llo',\n b'What is the weather tomorrow',\n b'G\\xc3\\xb6\\xc3\\xb6dnight',\n b'\\xf0\\x9f\\x98\\x8a']"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_utf8 = [s.encode('UTF-8') for s in [u'hÃllo', u'What is the weather tomorrow', u'Göödnight', u'😊']]\n",
    "batch_utf8"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.RaggedTensor [[104, 195, 108, 108, 111],\n [87, 104, 97, 116, 32, 105, 115, 32, 116, 104, 101, 32, 119, 101, 97, 116,\n  104, 101, 114, 32, 116, 111, 109, 111, 114, 114, 111, 119]               ,\n [71, 246, 246, 100, 110, 105, 103, 104, 116], [128522]]>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_chars_ragged = tf.strings.unicode_decode(batch_utf8, input_encoding='UTF-8')\n",
    "batch_chars_ragged\n",
    "# 生成了RaggedTensor 不同维度长度不同"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[104 195 108 108 111]\n",
      "[ 87 104  97 116  32 105 115  32 116 104 101  32 119 101  97 116 104 101\n",
      " 114  32 116 111 109 111 114 114 111 119]\n",
      "[ 71 246 246 100 110 105 103 104 116]\n",
      "[128522]\n"
     ]
    }
   ],
   "source": [
    "for each in batch_chars_ragged.numpy():\n",
    "    print(each)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "TensorShape([4, 28])"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 对于RaggedTensor 可以使用to_tensor或者to_sparse进行padding\n",
    "batch_chars_ragged.to_tensor().shape\n",
    "# to_tensor padding到了28维"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(43,), dtype=int32, numpy=\narray([   104,    195,    108,    108,    111,     87,    104,     97,\n          116,     32,    105,    115,     32,    116,    104,    101,\n           32,    119,    101,     97,    116,    104,    101,    114,\n           32,    116,    111,    109,    111,    114,    114,    111,\n          119,     71,    246,    246,    100,    110,    105,    103,\n          104,    116, 128522], dtype=int32)>"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_chars_ragged.to_sparse().values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'cat', b'dog', b'co'], dtype=object)>"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_encode(tf.ragged.constant([[99,97,116],[100,111,103],[99,111]]), output_encoding='UTF-8')\n",
    "# unicode_encode的时候可以输入RaggedTensor 进行encode 转化为Tensor"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(4,), dtype=string, numpy=\narray([b'h\\xc3\\x83llo\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00',\n       b'What is the weather tomorrow',\n       b'G\\xc3\\xb6\\xc3\\xb6dnight\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00',\n       b'\\xf0\\x9f\\x98\\x8a\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00'],\n      dtype=object)>"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_encode(batch_chars_ragged.to_tensor(),output_encoding='UTF-8')\n",
    "# 值得注意的是 如果直接把padding之后的tensor调用unicode_encode 会有很多padding的0值"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(4,), dtype=string, numpy=\narray([b'h\\xc3\\x83llo', b'What is the weather tomorrow',\n       b'G\\xc3\\xb6\\xc3\\xb6dnight', b'\\xf0\\x9f\\x98\\x8a'], dtype=object)>"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 需要将其处理回 RaggedTensor\n",
    "tf.strings.unicode_encode(tf.RaggedTensor.from_tensor(batch_chars_ragged.to_tensor(),padding=0), output_encoding='UTF-8')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## unicode对象的操作\n",
    "1. character length             tf.strings.length\n",
    "2. character substrings         tf.strings.substr\n",
    "3. split unicode strings        tf.strings.unicode_split\n",
    "4. byte offset for characters   tf.strings.unicode_decode_with_offsets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "b'Thanks \\xf0\\x9f\\x98\\x8a'"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thanks = u'Thanks 😊'.encode('UTF-8')\n",
    "thanks"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 bytes, 8 UTF-8 characters\n"
     ]
    }
   ],
   "source": [
    "# 使用tf.strings.length表示多少个单位 默认使用'BYTE' 还可以使用'UTF8-CHAR' 'UTF16_CHAR'等\n",
    "num_bytes = tf.strings.length(thanks).numpy()\n",
    "num_chars = tf.strings.length(thanks, unit='UTF8_CHAR').numpy()\n",
    "print(f'{num_bytes} bytes, {num_chars} UTF-8 characters')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(), dtype=string, numpy=b'\\x98\\x8a'>"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用tf.strings.substr 接收unit参数， 使用它确定substring的开始位置pos和len长度\n",
    "tf.strings.substr(thanks, pos=9, len=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(8,), dtype=string, numpy=\narray([b'T', b'h', b'a', b'n', b'k', b's', b' ', b'\\xf0\\x9f\\x98\\x8a'],\n      dtype=object)>"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用tf.strings.unicode_split将unicode strings转为substrings\n",
    "tf.strings.unicode_split(thanks, input_encoding='UTF-8')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At byte offset 0: codepoint 127880\n",
      "At byte offset 4: codepoint 127881\n",
      "At byte offset 8: codepoint 127882\n"
     ]
    }
   ],
   "source": [
    "# tf.strings.unicode_decode_with_offsets 在decode的基础上，加上了offset offset即为不同的character的起始byte的位置\n",
    "codepoints, offsets = tf.strings.unicode_decode_with_offsets(u'🎈🎉🎊', 'UTF-8')\n",
    "for (codepoint, offset) in zip(codepoints.numpy(), offsets.numpy()):\n",
    "  print('At byte offset {}: codepoint {}'.format(offset, codepoint))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## unicode scripts\n",
    "tf.strings.unicode_script方法可以表征character所在的语言"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17  8]\n"
     ]
    }
   ],
   "source": [
    "# unicode 33464代表汉字芸 1041代表西里尔语Б\n",
    "# 可以直接处理list对象\n",
    "uscript = tf.strings.unicode_script([33464, 1041])  # ['芸', 'Б']\n",
    "print(uscript.numpy())  # [17, 8] == [USCRIPT_HAN, USCRIPT_CYRILLIC]\n",
    "# unicode_script之后得到了17->汉语 8->西里尔语"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.RaggedTensor [[25, 25, 25, 25, 25],\n [25, 25, 25, 25, 0, 25, 25, 0, 25, 25, 25, 0, 25, 25, 25, 25, 25, 25, 25,\n  0, 25, 25, 25, 25, 25, 25, 25, 25]                                      ,\n [25, 25, 25, 25, 25, 25, 25, 25, 25], [0]]>"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 也可以处理RaggedTensor 和 Tensor对象\n",
    "tf.strings.unicode_script(batch_chars_ragged)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 实践：分词\n",
    "分词就是把一个句子变成word-like units\n",
    "在如英语的语言中，可以直接使用空格分词\n",
    "但是在汉语或者日语中，没有空格，直接用字进行分割\n",
    "而在类似于德语的场景中，可能需要对长词 进行分割\n",
    "最后，一段文本中可能有多种语言 如我的名字是Bob"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "# 初始文本 dtype unicode string\n",
    "sentence_texts = [u'Hello, world. 你好鸭~', u'你好，世界。Yes, well Done.', u'世界こんにちは']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.RaggedTensor [[72, 101, 108, 108, 111, 44, 32, 119, 111, 114, 108, 100, 46, 32, 20320,\n  22909, 40493, 126]                                                     ,\n [20320, 22909, 65292, 19990, 30028, 12290, 89, 101, 115, 44, 32, 119, 101,\n  108, 108, 32, 68, 111, 110, 101, 46]                                     ,\n [19990, 30028, 12371, 12435, 12395, 12385, 12399]]>"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将string变为int向量表示\n",
    "sentence_texts_codepoint = tf.strings.unicode_decode(sentence_texts, input_encoding='UTF-8')\n",
    "sentence_texts_codepoint"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.RaggedTensor [[25, 25, 25, 25, 25, 0, 0, 25, 25, 25, 25, 25, 0, 0, 17, 17, 17, 0],\n [17, 17, 0, 17, 17, 0, 25, 25, 25, 0, 0, 25, 25, 25, 25, 0, 25, 25, 25, 25,\n  0]                                                                        ,\n [17, 17, 20, 20, 20, 20, 20]]>"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 找到其对应的语言 unicode_script\n",
    "sentence_texts_language = tf.strings.unicode_script(sentence_texts_codepoint)\n",
    "sentence_texts_language"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [],
   "source": [
    "all_sentence_list = list()\n",
    "sentence_count = sentence_texts_language.shape[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "# 按照语言的连续性进行分割\n",
    "# method1 比较笨 用的滑动窗口-----------------------------------------------------------------------------\n",
    "\n",
    "for index, sentence in enumerate(sentence_texts_language):\n",
    "    # print(index)\n",
    "    # print(sentence)\n",
    "    sentence_codepoint = sentence_texts_codepoint[index]\n",
    "    len_ = sentence.shape[0]\n",
    "    left = 0\n",
    "    right = 0\n",
    "    while right < len_ -1:\n",
    "        if sentence[right] != sentence[right+1]:\n",
    "            sub_sentence = sentence_codepoint[left:right+1].numpy()\n",
    "            all_sentence_list.append(sub_sentence)\n",
    "            left = right + 1\n",
    "        right = right + 1\n",
    "    last_sentence = sentence_codepoint[left:len_].numpy()\n",
    "    all_sentence_list.append(last_sentence)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "data": {
      "text/plain": "[array([ 72, 101, 108, 108, 111], dtype=int32),\n array([44, 32], dtype=int32),\n array([119, 111, 114, 108, 100], dtype=int32),\n array([46, 32], dtype=int32),\n array([20320, 22909, 40493], dtype=int32),\n array([126], dtype=int32),\n array([20320, 22909], dtype=int32),\n array([65292], dtype=int32),\n array([19990, 30028], dtype=int32),\n array([12290], dtype=int32),\n array([ 89, 101, 115], dtype=int32),\n array([44, 32], dtype=int32),\n array([119, 101, 108, 108], dtype=int32),\n array([32], dtype=int32),\n array([ 68, 111, 110, 101], dtype=int32),\n array([46], dtype=int32),\n array([19990, 30028], dtype=int32),\n array([12371, 12435, 12395, 12385, 12399], dtype=int32)]"
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sentence_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.RaggedTensor [[72, 101, 108, 108, 111], [44, 32], [119, 111, 114, 108, 100], [46, 32],\n [20320, 22909, 40493], [126], [20320, 22909], [65292], [19990, 30028],\n [12290], [89, 101, 115], [44, 32], [119, 101, 108, 108], [32],\n [68, 111, 110, 101], [46], [19990, 30028],\n [12371, 12435, 12395, 12385, 12399]]>"
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_char_codepoint = tf.ragged.constant(all_sentence_list)\n",
    "word_char_codepoint\n",
    "# method1 比较笨 用的滑动窗口-----------------------------------------------------------------------------"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(3, 1), dtype=bool, numpy=\narray([[ True],\n       [ True],\n       [ True]])>"
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# method2 官方写的高级方法-----------------------------------------------------------------------------\n",
    "tf.fill([sentence_texts_language.nrows(), 1], True)\n",
    "# 这是代表每句的开头都是分隔点"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.RaggedTensor [[False, False, False, False, True, False, True, False, False, False, False,\n  True, False, True, False, False, True]                                    ,\n [False, True, True, False, True, True, False, False, True, False, True,\n  False, False, False, True, True, False, False, False, True]           ,\n [False, True, False, False, False, False]]>"
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.not_equal(sentence_texts_language[:, 1:], sentence_texts_language[:, :-1])\n",
    "# 使用交错位置即一个从头开始考虑 另一个从第二个位置开始考虑 不断往后 有不同的就是分隔点-1\n",
    "# 使用not_equal方法十分优美"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.RaggedTensor [[True, False, False, False, False, True, False, True, False, False, False,\n  False, True, False, True, False, False, True]                            ,\n [True, False, True, True, False, True, True, False, False, True, False,\n  True, False, False, False, True, True, False, False, False, True]     ,\n [True, False, True, False, False, False, False]]>"
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_char_starts_word = tf.concat(\n",
    "    [tf.fill([sentence_texts_language.nrows(), 1], True),\n",
    "     tf.not_equal(sentence_texts_language[:, 1:], sentence_texts_language[:, :-1])],\n",
    "    axis=1)\n",
    "sentence_char_starts_word\n",
    "# tf.not_equal是分隔点-1 再拼接上刚开始的句首的True 就刚好对应了"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(46,), dtype=bool, numpy=\narray([ True, False, False, False, False,  True, False,  True, False,\n       False, False, False,  True, False,  True, False, False,  True,\n        True, False,  True,  True, False,  True,  True, False, False,\n        True, False,  True, False, False, False,  True,  True, False,\n       False, False,  True,  True, False,  True, False, False, False,\n       False])>"
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_char_starts_word.values\n",
    "# RaggedTensor的values会将其拉直"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(18, 1), dtype=int64, numpy=\narray([[ 0],\n       [ 5],\n       [ 7],\n       [12],\n       [14],\n       [17],\n       [18],\n       [20],\n       [21],\n       [23],\n       [24],\n       [27],\n       [29],\n       [33],\n       [34],\n       [38],\n       [39],\n       [41]])>"
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.where(sentence_char_starts_word.values)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(18,), dtype=int64, numpy=\narray([ 0,  5,  7, 12, 14, 17, 18, 20, 21, 23, 24, 27, 29, 33, 34, 38, 39,\n       41])>"
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_starts = tf.squeeze(tf.where(sentence_char_starts_word.values), axis=1)\n",
    "word_starts\n",
    "# 这样就把True的部分找出来"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.RaggedTensor [[72, 101, 108, 108, 111], [44, 32], [119, 111, 114, 108, 100], [46, 32],\n [20320, 22909, 40493], [126], [20320, 22909], [65292], [19990, 30028],\n [12290], [89, 101, 115], [44, 32], [119, 101, 108, 108], [32],\n [68, 111, 110, 101], [46], [19990, 30028],\n [12371, 12435, 12395, 12385, 12399]]>"
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 由于word_starts的表示方式是拉直的 RaggedTensor就有from_row_start方法进行切片\n",
    "word_char_codepoint_ = tf.RaggedTensor.from_row_starts(\n",
    "    values=sentence_texts_codepoint.values,\n",
    "    row_starts=word_starts\n",
    ")\n",
    "word_char_codepoint_\n",
    "# method2 官方写的高级方法-----------------------------------------------------------------------------"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.RaggedTensor [[1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1],\n [1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1],\n [1, 0, 1, 0, 0, 0, 0]]>"
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  将True False强制类型转换为int\n",
    "tf.cast(sentence_char_starts_word, tf.int64)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(3,), dtype=int64, numpy=array([ 6, 10,  2])>"
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_num_words = tf.reduce_sum(\n",
    "    tf.cast(sentence_char_starts_word, tf.int64),\n",
    "    axis=1)\n",
    "sentence_num_words\n",
    "# 这样就能计算出分隔点的位置"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[[72, 101, 108, 108, 111], [44, 32], [119, 111, 114, 108, 100], [46, 32],\n",
      "  [20320, 22909, 40493], [126]]                                           ,\n",
      " [[20320, 22909], [65292], [19990, 30028], [12290], [89, 101, 115],\n",
      "  [44, 32], [119, 101, 108, 108], [32], [68, 111, 110, 101], [46]] ,\n",
      " [[19990, 30028], [12371, 12435, 12395, 12385, 12399]]]>\n"
     ]
    }
   ],
   "source": [
    "# 用from_row_lengths接口 能够将本来就是RaggedTensor合并为一个新的RaggedTensor\n",
    "# word_char_codepoint是分割开的RaggedTensor\n",
    "sentence_word_char_codepoint = tf.RaggedTensor.from_row_lengths(\n",
    "    values=word_char_codepoint,\n",
    "    row_lengths=sentence_num_words)\n",
    "print(sentence_word_char_codepoint)\n",
    "# 得到了按照数量合并的RaggedTensor 由RaggedTensor组成的RaggedTensor"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.RaggedTensor [[72, 101, 108, 108, 111], [44, 32], [119, 111, 114, 108, 100], [46, 32],\n [20320, 22909, 40493], [126]]>"
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_word_char_codepoint[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "data": {
      "text/plain": "[[b'Hello',\n  b', ',\n  b'world',\n  b'. ',\n  b'\\xe4\\xbd\\xa0\\xe5\\xa5\\xbd\\xe9\\xb8\\xad',\n  b'~'],\n [b'\\xe4\\xbd\\xa0\\xe5\\xa5\\xbd',\n  b'\\xef\\xbc\\x8c',\n  b'\\xe4\\xb8\\x96\\xe7\\x95\\x8c',\n  b'\\xe3\\x80\\x82',\n  b'Yes',\n  b', ',\n  b'well',\n  b' ',\n  b'Done',\n  b'.'],\n [b'\\xe4\\xb8\\x96\\xe7\\x95\\x8c',\n  b'\\xe3\\x81\\x93\\xe3\\x82\\x93\\xe3\\x81\\xab\\xe3\\x81\\xa1\\xe3\\x81\\xaf']]"
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_encode(sentence_word_char_codepoint, 'UTF-8').to_list()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}