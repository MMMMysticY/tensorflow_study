{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# word embedding\n",
    "对自然语言处理进行数字化 变为数字所表示的向量，才可以经过神经网络进行处理\n",
    "有一些方法如：\n",
    "1. one-hot 很明显太过于稀疏\n",
    "2. word with a unique number 很难找到一个好的编码 同时无法衡量两个词之间的关系\n",
    "3. word embeddings word embeddings是使用浮点数向量进行表示的，同时这些数是学习得到的 而且维度可以自行制定一般从8-1024维不等"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import string\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D\n",
    "from tensorflow.keras.layers import TextVectorization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "tf.get_logger().setLevel('ERROR')\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1' # 使用 GPU 1\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0],True)\n",
    "logical_devices = tf.config.list_logical_devices(\"GPU\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "'/home/wy'"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 数据部分"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "data_dir = 'tensorflow_study/tensorflow-text/data_dir/'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "'tensorflow_study/tensorflow-text/data_dir/aclImdb'"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Imdb_data_dir = os.path.join(data_dir, 'aclImdb')\n",
    "Imdb_data_dir"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "['urls_pos.txt',\n 'urls_unsup.txt',\n 'neg',\n 'pos',\n 'unsupBow.feat',\n 'labeledBow.feat',\n 'urls_neg.txt']"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 数据集\n",
    "train_dir = os.path.join(Imdb_data_dir, 'train')\n",
    "os.listdir(train_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n",
      "Using 20000 files for training.\n"
     ]
    }
   ],
   "source": [
    "# 通过text_dataset_from_directory创建tf.data.Dataset对象\n",
    "batch_size = 64\n",
    "seed = 123\n",
    "train_ds = keras.utils.text_dataset_from_directory(\n",
    "    directory=train_dir,\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    subset='training',\n",
    "    seed=seed\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n",
      "Using 5000 files for validation.\n"
     ]
    }
   ],
   "source": [
    "val_ds = keras.utils.text_dataset_from_directory(\n",
    "    directory=train_dir,\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    subset='validation',\n",
    "    seed=seed\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 b'Jason Bourne sits in a dusty room in with blood on his hands, trying to make sense of what he\\'s just done. Meanwhile, a CIA chief in NYC outlines the agency\\'s response to what\\'s just happened on screen. An American flag stands proudly on the centre of his desk in the foreground of the shot, but as he speaks, it slips out of focus as his plan veers into morally dubious territory, as if it doesn\\'t want to be associated with the course of action the government man decides is necessary in the interests of national security.<br /><br />This shot effectively captures the mood of the film. As well as portraying Bourne\\'s quest to find out how he became Jason Bourne, Ultimatum is also an examination of the human costs of the measures taken to protect us in the interests of stability and security.<br /><br />It is also probably the best film you\\'ll see in the cinema this year. <br /><br />It\\'s just so intense. Bourne says to Simon Ross (Considine) \"This isn\\'t some newspaper story, this is real\" and in the audience you almost believe him. The camera shakes, but remains steady enough for you to see everything and feel like you\\'re there with Bourne as he tries to elude his pursuers, and the performances are so good that these guys seem as though they are the characters they\\'re portraying, instead of just being actors performing well-written roles. The action scenes are so brutally fast-paced and well choreographed that they seem instinctive instead of planned to the minutest movement; the stunt-work is nothing short of amazing.<br /><br />The pacing is just incredible. It keeps driving forward towards its conclusion, but not so fast that it leaves you struggling to piece together the plot; the script delivers the information you need as quickly and clearly as possible before moving on to the next tense action set-piece. While they\\'re often simple (the Waterloo sequence is essentially just a man on a phone being watched by a man on a phone) they\\'re charged with such dramatic intensity that you can\\'t take your eyes off them. The film is just so focused on powering forwards that you can\\'t help being swept along by it.<br /><br />With its intense action set-pieces, brilliantly paced storyline, and intelligent examination of the decisions made in the name of national security, the Bourne series is one that accurately captures the ambiguities of our age. Ultimatum is its peak.'\n",
      "1 b\"This movie has it all. It is a classic depiction of the events that surrounded the migration of thousands of Cuban refugees. Antonio Montana(played by Al Pacino), is just one of the thousands to get a chance to choose his destiny in America. This cinematic yet extremely accurate depiction of Miamis' Drug Empire is astonishing. Brian DePalma does an amazing job directing this picture, so much that, the viewer becomes involved with both the storyline, as well as every character in the cast. With Tony's characters' pressence being so believable and strong, Brian DePalma brang out the raw talent exposed by Steven Bauer(Manny, Tony's best Friend), Mary Elizabeth Mastantonio(Gina, Tony's Sister), Robert Loggia(Frank, Tony's Boss)and Michelle Pfeiffer(Elvira, Frank's Wife). I enjoyed every minute watching this movie, and still watch it on a weekly basis. On this year, the 20th Anniversary of this classic crime movie, I for one am a true believer that in another 20 years people will still refer to this movie in astonishing numbers. With other crime movies being so dramatic I find, this movie is a shock to the system.\"\n"
     ]
    }
   ],
   "source": [
    "for text_batch, label_batch in train_ds.take(1):\n",
    "    for i in range(2):\n",
    "        print(label_batch[i].numpy(), text_batch[i].numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Embedding层 将int->vector"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 使用embedding layer进行embedding\n",
    "# Embedding的效果是将从一个数字表示映射到一个稠密向量 维度都是人为确定的"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "embedding_layer = keras.layers.Embedding(1000, 16)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-0.00936151,  0.03384093, -0.02365005, -0.00131559,  0.04822022,\n         0.0353758 , -0.0362368 ,  0.03327969, -0.02155138, -0.03955991,\n         0.01556111,  0.04476155,  0.03947124, -0.01426164,  0.00703765,\n        -0.02079763],\n       [ 0.0073679 ,  0.02831913, -0.01844732,  0.02355484,  0.02193354,\n        -0.04042045, -0.01318113, -0.03431385,  0.03917738, -0.04211224,\n         0.04126408,  0.02613726,  0.01594051,  0.04059455,  0.00451093,\n         0.02150061],\n       [-0.04095035,  0.03070948, -0.03090088, -0.01668663, -0.0235302 ,\n        -0.00186567, -0.0433871 ,  0.04784938,  0.00201153, -0.04484543,\n         0.00599276,  0.02481134,  0.01584301, -0.0457539 , -0.04185405,\n        -0.04755386]], dtype=float32)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = embedding_layer(tf.constant([1, 2, 3]))\n",
    "result.numpy()\n",
    "# embedding_layer就将1 2 3 三个int常量转化为了embedding的16维表示"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 而对于一般的文本任务 embedding_layer的输入是[samples, seq_len]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2, 3, 16), dtype=float32, numpy=\narray([[[-0.00936151,  0.03384093, -0.02365005, -0.00131559,\n          0.04822022,  0.0353758 , -0.0362368 ,  0.03327969,\n         -0.02155138, -0.03955991,  0.01556111,  0.04476155,\n          0.03947124, -0.01426164,  0.00703765, -0.02079763],\n        [ 0.0073679 ,  0.02831913, -0.01844732,  0.02355484,\n          0.02193354, -0.04042045, -0.01318113, -0.03431385,\n          0.03917738, -0.04211224,  0.04126408,  0.02613726,\n          0.01594051,  0.04059455,  0.00451093,  0.02150061],\n        [-0.04095035,  0.03070948, -0.03090088, -0.01668663,\n         -0.0235302 , -0.00186567, -0.0433871 ,  0.04784938,\n          0.00201153, -0.04484543,  0.00599276,  0.02481134,\n          0.01584301, -0.0457539 , -0.04185405, -0.04755386]],\n\n       [[ 0.02101446, -0.04563413, -0.03810685, -0.02001367,\n          0.04243615, -0.0263909 , -0.00751717, -0.03385391,\n         -0.04545246, -0.04952151, -0.04655317,  0.03153383,\n          0.01096991, -0.00342498,  0.04553661,  0.02468297],\n        [ 0.03127782,  0.04533023,  0.02877489,  0.00640997,\n         -0.04110688, -0.01836171,  0.04489657, -0.01540933,\n          0.01838208, -0.02497247,  0.00269771, -0.01541907,\n         -0.00600568, -0.0254023 , -0.02177305,  0.0479548 ],\n        [ 0.04504934, -0.031473  ,  0.00999683,  0.01299795,\n         -0.00772746, -0.0140375 ,  0.01609499,  0.02957879,\n         -0.04248036, -0.03856332, -0.03368501, -0.02166319,\n          0.0370524 ,  0.03831811, -0.04097795, -0.00065341]]],\n      dtype=float32)>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_batched = embedding_layer(tf.constant([[1,2,3], [6,7,8]]))\n",
    "result_batched\n",
    "# 输入[batch=2, seq_len=3] 输出[batch=2, seq_len=3, feature=16]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.RaggedTensor [[[-0.0093615055, 0.03384093, -0.02365005, -0.0013155937, 0.04822022,\n   0.0353758, -0.0362368, 0.03327969, -0.021551384, -0.039559912,\n   0.015561115, 0.04476155, 0.039471235, -0.014261641, 0.007037651,\n   -0.020797634],\n  [0.007367898, 0.028319132, -0.018447317, 0.023554835, 0.021933544,\n   -0.04042045, -0.013181128, -0.034313846, 0.039177384, -0.042112242,\n   0.041264083, 0.026137259, 0.015940513, 0.04059455, 0.004510928,\n   0.021500614],\n  [-0.040950347, 0.030709479, -0.030900884, -0.01668663, -0.023530198,\n   -0.0018656738, -0.043387104, 0.047849383, 0.0020115264, -0.04484543,\n   0.005992759, 0.024811339, 0.015843008, -0.045753896, -0.041854046,\n   -0.047553863]]                                                      ,\n [[0.007367898, 0.028319132, -0.018447317, 0.023554835, 0.021933544,\n   -0.04042045, -0.013181128, -0.034313846, 0.039177384, -0.042112242,\n   0.041264083, 0.026137259, 0.015940513, 0.04059455, 0.004510928,\n   0.021500614],\n  [-0.040950347, 0.030709479, -0.030900884, -0.01668663, -0.023530198,\n   -0.0018656738, -0.043387104, 0.047849383, 0.0020115264, -0.04484543,\n   0.005992759, 0.024811339, 0.015843008, -0.045753896, -0.041854046,\n   -0.047553863]]                                                      ,\n [[-0.0093615055, 0.03384093, -0.02365005, -0.0013155937, 0.04822022,\n   0.0353758, -0.0362368, 0.03327969, -0.021551384, -0.039559912,\n   0.015561115, 0.04476155, 0.039471235, -0.014261641, 0.007037651,\n   -0.020797634],\n  [0.038450826, -0.020067394, 0.010074388, 0.0367033, -0.010028504,\n   -0.04761019, -0.020760942, 0.019002806, -0.026388967, 0.0028374307,\n   0.015026223, 0.035266105, 0.002152741, 0.027829442, 0.003253568,\n   -0.028677953],\n  [0.021014456, -0.04563413, -0.038106848, -0.020013666, 0.04243615,\n   -0.026390899, -0.00751717, -0.03385391, -0.045452464, -0.049521506,\n   -0.046553172, 0.031533826, 0.0109699145, -0.0034249797, 0.04553661,\n   0.024682965],\n  [0.031277824, 0.04533023, 0.028774891, 0.0064099655, -0.04110688,\n   -0.01836171, 0.04489657, -0.015409328, 0.018382084, -0.024972474,\n   0.0026977062, -0.015419066, -0.006005682, -0.025402296, -0.021773053,\n   0.0479548]]                                                          ]>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_batched_ragged = embedding_layer(tf.ragged.constant([[1,2,3],[2,3],[1,5,6,7]]))\n",
    "result_batched_ragged\n",
    "# 同时还可以处理RaggedTensor"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## TextVectorization string->int"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "def custom_standardization(input_data):\n",
    "    lowercase = tf.strings.lower(input_data) # 转成小写字母\n",
    "    stripped_html = tf.strings.regex_replace(lowercase, '<br />', ' ') # 由于文本中有很多html的<br /> tag 使用正则替换为空格\n",
    "    return tf.strings.regex_replace(stripped_html,'[%s]' % re.escape(string.punctuation), '') # 去掉标点符号"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "'[!\"\\\\#\\\\$%\\\\&\\'\\\\(\\\\)\\\\*\\\\+,\\\\-\\\\./:;<=>\\\\?@\\\\[\\\\\\\\\\\\]\\\\^_`\\\\{\\\\|\\\\}\\\\~]'"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'[%s]' % re.escape(string.punctuation) # 这应该是所有的标点符号集合"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "sequence_length = 100\n",
    "# 设置词典大小和一个句子中单词个数"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "vectorize_layer = TextVectorization(\n",
    "    standardize = custom_standardization,\n",
    "    max_tokens = vocab_size,\n",
    "    output_mode = 'int',                     # 设置输出为int\n",
    "    output_sequence_length = sequence_length # 设置seq_len最大长度\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "text_ds = train_ds.map(lambda x,y :x) # train_ds本来的组织形式是text,label的形式 使用map+lambda表达式将其仅保留text"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "vectorize_layer.adapt(text_ds)\n",
    "# 使用text_ds的文本进行训练TextVectorization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(100,), dtype=int64, numpy=\narray([ 10, 118,  36,  22,  23,  10, 116,   1,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0])>"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize_layer('I know who you are, I love tensorflow.') # tensorflow->1 应该是unknown"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_sentence:\n",
      "b'It\\'s always nice to see Angela Bassett getting to do a role that she can really sink her teeth into. She is at times intense, funny and even sexy in her role as Lena, a \"colored\" woman forced to make a home on a desolate mudbank just outside of Cape Town, South Africa. Danny Glover is also good in a not entirely sympathetic role as her partner, Boesman. Willie Jonah gives a finely nuanced performance as the stranger that discovers Boesman and Lena\\'s new living area. It\\'s not often that you get a chance to see an intelligent film dealing with mature themes. Although it is based on a play, the late director John Berry (who also directed Claudine) opens the material up by having the film shot in the widescreen Cinemascope format. He also keeps things visually interesting through the creative blocking of actors and by showing us things only mentioned in the play. Just like Diahann Carroll in Claudine, John Berry may have directed Angela Bassett into an Academy Award nomination. This is definitely a film worth searching for.'\n",
      "after vectorize_layer:\n",
      "tf.Tensor(\n",
      "[  29  201  315    6   65 4866    1  373    6   81    4  207   12   54\n",
      "   68   62 5045   39 2545   82   54    7   30  210 1536  158    3   53\n",
      " 1254    8   39  207   14 4159    4 8333  245  892    6   96    4  339\n",
      "   20    4 8911    1   40  992    5 6434  512 1192 2431 1707 3929    7\n",
      "   79   49    8    4   21 1107 2230  207   14   39 1876    1 4976    1\n",
      "  386    4 8889 7503  234   14    2 2899   12 1932    1    3    1  157\n",
      "  580 1602   29   21  387   12   22   76    4  563    6   65   33 1106\n",
      "   19 2009], shape=(100,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for text_batch in text_ds.take(1):\n",
    "    for i in range(1):\n",
    "        print('raw_sentence:')\n",
    "        print(text_batch[i].numpy())\n",
    "        print('after vectorize_layer:')\n",
    "        print(vectorize_layer(text_batch[i]))\n",
    "\n",
    "# 将一个sentence转化为了int的向量表示"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 模型部分\n",
    "vectorize_layer\n",
    "Embedding\n",
    "GlobalAveragePooling1D\n",
    "Dense\n",
    "Dense"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "embedding_dim = 16\n",
    "model = Sequential([\n",
    "    vectorize_layer,\n",
    "    Embedding(input_dim=vocab_size,output_dim=embedding_dim,name='Embedding'),\n",
    "    GlobalAveragePooling1D(),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1)\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir='tensorflow_study/tensorflow-text/log_dir/')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss = keras.losses.BinaryCrossentropy(from_logits=True), # 二分类 最后没有用激活函数sigmoid\n",
    "    metrics=['accuracy']\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "313/313 [==============================] - 5s 13ms/step - loss: 0.6263 - accuracy: 0.5565 - val_loss: 0.5005 - val_accuracy: 0.7170\n",
      "Epoch 2/20\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.4020 - accuracy: 0.8135 - val_loss: 0.3880 - val_accuracy: 0.8048\n",
      "Epoch 3/20\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.3085 - accuracy: 0.8662 - val_loss: 0.3716 - val_accuracy: 0.8196\n",
      "Epoch 4/20\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.2601 - accuracy: 0.8913 - val_loss: 0.3781 - val_accuracy: 0.8198\n",
      "Epoch 5/20\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.2258 - accuracy: 0.9078 - val_loss: 0.3961 - val_accuracy: 0.8200\n",
      "Epoch 6/20\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.1989 - accuracy: 0.9204 - val_loss: 0.4212 - val_accuracy: 0.8170\n",
      "Epoch 7/20\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 0.1763 - accuracy: 0.9306 - val_loss: 0.4520 - val_accuracy: 0.8130\n",
      "Epoch 8/20\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 0.1568 - accuracy: 0.9403 - val_loss: 0.4878 - val_accuracy: 0.8074\n",
      "Epoch 9/20\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.1393 - accuracy: 0.9485 - val_loss: 0.5283 - val_accuracy: 0.8046\n",
      "Epoch 10/20\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.1235 - accuracy: 0.9557 - val_loss: 0.5730 - val_accuracy: 0.8022\n",
      "Epoch 11/20\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.1090 - accuracy: 0.9628 - val_loss: 0.6221 - val_accuracy: 0.7978\n",
      "Epoch 12/20\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.0956 - accuracy: 0.9694 - val_loss: 0.6756 - val_accuracy: 0.7954\n",
      "Epoch 13/20\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 0.0832 - accuracy: 0.9754 - val_loss: 0.7332 - val_accuracy: 0.7926\n",
      "Epoch 14/20\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.0718 - accuracy: 0.9809 - val_loss: 0.7951 - val_accuracy: 0.7898\n",
      "Epoch 15/20\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 0.0613 - accuracy: 0.9848 - val_loss: 0.8605 - val_accuracy: 0.7894\n",
      "Epoch 16/20\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.0519 - accuracy: 0.9890 - val_loss: 0.9287 - val_accuracy: 0.7856\n",
      "Epoch 17/20\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.0434 - accuracy: 0.9916 - val_loss: 1.0001 - val_accuracy: 0.7856\n",
      "Epoch 18/20\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 0.0358 - accuracy: 0.9944 - val_loss: 1.0705 - val_accuracy: 0.7846\n",
      "Epoch 19/20\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.0295 - accuracy: 0.9965 - val_loss: 1.1417 - val_accuracy: 0.7852\n",
      "Epoch 20/20\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.0243 - accuracy: 0.9973 - val_loss: 1.2061 - val_accuracy: 0.7850\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x7f7f3c1b7fd0>"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=20,\n",
    "    callbacks=[tensorboard_callback]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " text_vectorization (TextVec  (None, 100)              0         \n",
      " torization)                                                     \n",
      "                                                                 \n",
      " Embedding (Embedding)       (None, 100, 16)           160000    \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 16)               0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                272       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 160,289\n",
      "Trainable params: 160,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 0.04382979, -0.00486052,  0.03430449, ..., -0.06809052,\n        -0.03361597,  0.02136711],\n       [ 0.07515999, -0.01429346,  0.06753578, ..., -0.06306358,\n        -0.00482039, -0.0447018 ],\n       [ 0.03830411, -0.08916663,  0.02888909, ..., -0.12979527,\n        -0.04456586, -0.04959089],\n       ...,\n       [ 0.4870867 ,  0.46741113,  0.4835528 , ..., -0.48341328,\n         0.5170282 ,  0.5436005 ],\n       [ 0.19580714,  0.21112469,  0.15403022, ..., -0.17184824,\n         0.14987457,  0.149738  ],\n       [-0.36725155, -0.3218097 , -0.35055414, ...,  0.263168  ,\n        -0.33849916, -0.33139604]], dtype=float32)"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 保存embedding layer的参数 其是一个[vocab_size, embedding_dim]的向量\n",
    "weights = model.get_layer('Embedding').get_weights()[0]\n",
    "weights"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "['',\n '[UNK]',\n 'the',\n 'and',\n 'a',\n 'of',\n 'to',\n 'is',\n 'in',\n 'it',\n 'i',\n 'this',\n 'that',\n 'was',\n 'as',\n 'with',\n 'for',\n 'movie',\n 'but',\n 'film',\n 'on',\n 'not',\n 'you',\n 'are',\n 'his',\n 'have',\n 'be',\n 'he',\n 'one',\n 'its',\n 'at',\n 'all',\n 'by',\n 'an',\n 'they',\n 'from',\n 'who',\n 'so',\n 'like',\n 'her',\n 'just',\n 'or',\n 'about',\n 'has',\n 'out',\n 'if',\n 'some',\n 'there',\n 'what',\n 'good',\n 'more',\n 'when',\n 'very',\n 'even',\n 'she',\n 'up',\n 'my',\n 'no',\n 'would',\n 'time',\n 'only',\n 'which',\n 'really',\n 'story',\n 'their',\n 'see',\n 'were',\n 'had',\n 'can',\n 'me',\n 'we',\n 'than',\n 'much',\n 'well',\n 'been',\n 'will',\n 'get',\n 'people',\n 'bad',\n 'also',\n 'other',\n 'do',\n 'into',\n 'great',\n 'first',\n 'because',\n 'how',\n 'most',\n 'him',\n 'dont',\n 'made',\n 'movies',\n 'then',\n 'them',\n 'way',\n 'films',\n 'make',\n 'could',\n 'any',\n 'after',\n 'too',\n 'characters',\n 'think',\n 'watch',\n 'being',\n 'two',\n 'many',\n 'seen',\n 'character',\n 'plot',\n 'little',\n 'never',\n 'acting',\n 'where',\n 'best',\n 'did',\n 'love',\n 'life',\n 'know',\n 'show',\n 'does',\n 'ever',\n 'your',\n 'better',\n 'over',\n 'end',\n 'still',\n 'off',\n 'these',\n 'here',\n 'scene',\n 'man',\n 'say',\n 'why',\n 'while',\n 'scenes',\n 'such',\n 'go',\n 'something',\n 'should',\n 'through',\n 'back',\n 'im',\n 'those',\n 'real',\n 'watching',\n 'doesnt',\n 'years',\n 'now',\n 'thing',\n 'though',\n 'another',\n 'actors',\n 'didnt',\n 'before',\n 'actually',\n 'nothing',\n 'new',\n 'funny',\n 'makes',\n 'work',\n 'find',\n 'look',\n 'same',\n 'old',\n 'going',\n 'part',\n 'few',\n 'lot',\n 'again',\n 'us',\n 'every',\n 'director',\n 'cast',\n 'want',\n 'thats',\n 'cant',\n 'quite',\n 'seems',\n 'young',\n 'things',\n 'pretty',\n 'world',\n 'around',\n 'down',\n 'however',\n 'got',\n 'fact',\n 'take',\n 'enough',\n 'both',\n 'own',\n 'give',\n 'between',\n 'original',\n 'horror',\n 'may',\n 'thought',\n 'series',\n 'ive',\n 'big',\n 'always',\n 'without',\n 'gets',\n 'isnt',\n 'right',\n 'long',\n 'role',\n 'point',\n 'almost',\n 'times',\n 'action',\n 'interesting',\n 'come',\n 'saw',\n 'theres',\n 'least',\n 'whole',\n 'done',\n 'must',\n 'comedy',\n 'bit',\n 'family',\n 'might',\n 'guy',\n 'minutes',\n 'music',\n 'anything',\n 'script',\n 'last',\n 'hes',\n 'far',\n 'since',\n 'feel',\n 'performance',\n 'probably',\n 'am',\n 'yet',\n 'sure',\n 'away',\n 'kind',\n 'rather',\n 'fun',\n 'worst',\n 'tv',\n 'woman',\n 'girl',\n 'played',\n 'making',\n 'anyone',\n 'found',\n 'each',\n 'having',\n 'comes',\n 'course',\n 'believe',\n 'our',\n 'day',\n 'although',\n 'goes',\n 'trying',\n 'shows',\n 'looks',\n 'especially',\n 'place',\n 'hard',\n 'put',\n 'different',\n 'wasnt',\n 'sense',\n 'maybe',\n 'once',\n 'ending',\n 'worth',\n 'reason',\n 'money',\n 'true',\n 'screen',\n 'set',\n 'job',\n 'main',\n 'looking',\n 'everything',\n 'watched',\n 'book',\n 'someone',\n 'dvd',\n 'said',\n 'later',\n 'takes',\n 'actor',\n 'play',\n 'plays',\n 'three',\n 'during',\n 'audience',\n 'together',\n 'instead',\n '2',\n 'effects',\n 'seem',\n 'version',\n '10',\n 'himself',\n 'everyone',\n 'seeing',\n 'night',\n 'special',\n 'left',\n 'beautiful',\n 'excellent',\n 'john',\n 'american',\n 'idea',\n 'house',\n 'nice',\n 'simply',\n 'shot',\n 'youre',\n 'high',\n 'kids',\n 'wife',\n 'black',\n 'else',\n 'less',\n 'read',\n 'war',\n 'fan',\n 'help',\n 'completely',\n 'year',\n 'second',\n 'star',\n 'friends',\n 'death',\n 'used',\n 'rest',\n 'try',\n 'mind',\n 'home',\n 'poor',\n 'men',\n 'classic',\n 'either',\n 'use',\n 'need',\n 'performances',\n 'given',\n 'wrong',\n 'hollywood',\n 'short',\n 'enjoy',\n 'until',\n 'father',\n 'boring',\n 'along',\n 'half',\n 'women',\n 'truly',\n 'next',\n 'dead',\n 'line',\n 'tell',\n 'start',\n 'came',\n 'production',\n 'remember',\n 'couple',\n 'wonderful',\n 'recommend',\n 'mean',\n 'others',\n 'awful',\n 'getting',\n 'stupid',\n 'full',\n 'face',\n 'let',\n 'terrible',\n 'understand',\n 'playing',\n 'perhaps',\n 'moments',\n 'camera',\n 'doing',\n 'sex',\n 'gives',\n 'often',\n 'definitely',\n 'itself',\n 'keep',\n 'episode',\n 'small',\n 'video',\n 'name',\n 'early',\n 'become',\n 'dialogue',\n 'school',\n 'person',\n 'perfect',\n 'lines',\n 'lost',\n 'stars',\n 'supposed',\n 'human',\n 'top',\n 'liked',\n 'sort',\n 'yes',\n 'felt',\n 'finally',\n 'case',\n 'title',\n 'couldnt',\n 'evil',\n 'entire',\n 'went',\n 'piece',\n 'problem',\n 'hope',\n 'live',\n 'written',\n 'cinema',\n 'absolutely',\n 'waste',\n 'budget',\n 'against',\n 'shes',\n 'picture',\n 'worse',\n 'fans',\n 'style',\n 'head',\n 'loved',\n 'certainly',\n 'white',\n 'entertaining',\n 'several',\n 'based',\n 'overall',\n 'direction',\n 'beginning',\n 'killer',\n 'example',\n 'becomes',\n 'boy',\n 'mother',\n 'id',\n 'oh',\n 'guys',\n 'care',\n 'seemed',\n 'mr',\n 'dark',\n 'turn',\n 'throughout',\n '3',\n '\\x96',\n 'drama',\n 'unfortunately',\n 'lives',\n 'despite',\n 'already',\n 'amazing',\n 'laugh',\n 'wanted',\n 'final',\n 'history',\n 'children',\n 'friend',\n 'low',\n 'fine',\n 'works',\n 'tries',\n 'wont',\n 'sound',\n 'guess',\n '1',\n 'totally',\n 'girls',\n 'youll',\n 'act',\n 'lead',\n 'humor',\n 'under',\n 'writing',\n 'past',\n 'wants',\n 'theyre',\n 'days',\n 'called',\n 'turns',\n 'behind',\n 'able',\n 'favorite',\n 'starts',\n 'enjoyed',\n 'quality',\n 'michael',\n 'flick',\n 'gave',\n 'game',\n 'child',\n 'viewer',\n 'soon',\n 'side',\n 'themselves',\n 'kill',\n 'genre',\n 'parts',\n 'sometimes',\n 'town',\n 'eyes',\n 'son',\n 'car',\n 'ones',\n 'brilliant',\n 'heart',\n 'thinking',\n 'expect',\n 'art',\n 'stuff',\n 'horrible',\n 'feeling',\n 'stories',\n 'late',\n 'etc',\n 'directed',\n 'decent',\n 'obviously',\n 'ill',\n 'actress',\n 'close',\n 'says',\n 'fight',\n 'moment',\n 'anyway',\n 'happens',\n 'killed',\n 'blood',\n 'highly',\n 'city',\n 'roles',\n 'heard',\n 'myself',\n 'cannot',\n 'run',\n 'hour',\n 'took',\n 'matter',\n 'particularly',\n 'leave',\n 'hand',\n 'wouldnt',\n 'hell',\n 'happened',\n 'kid',\n 'extremely',\n 'except',\n 'wonder',\n 'involved',\n 'attempt',\n 'chance',\n 'strong',\n 'police',\n 'obvious',\n 'told',\n 'happen',\n 'complete',\n 'group',\n 'coming',\n 'lack',\n 'violence',\n 'james',\n 'alone',\n 'voice',\n 'including',\n 'daughter',\n 'type',\n 'living',\n 'experience',\n 'murder',\n 'please',\n 'ago',\n 'age',\n 'looked',\n 'yourself',\n 'interest',\n 'god',\n 'score',\n 'ok',\n 'save',\n 'number',\n 'shown',\n 'stop',\n 'career',\n 'ends',\n 'annoying',\n 'none',\n 'lets',\n 'hilarious',\n 'usually',\n 'simple',\n 'taken',\n 'slow',\n 'crap',\n 'cinematography',\n 'usual',\n 'scary',\n 'exactly',\n 'possible',\n 'mostly',\n 'david',\n 'song',\n 'opening',\n 'sad',\n 'released',\n 'across',\n 'seriously',\n 'whose',\n 'known',\n 'started',\n 'relationship',\n 'hours',\n 'episodes',\n 'musical',\n 'finds',\n 'hit',\n 'serious',\n 'cut',\n 'english',\n 'cool',\n 'huge',\n 'brother',\n 'reality',\n 'jokes',\n 'shots',\n 'opinion',\n 'today',\n 'change',\n 'order',\n 'gore',\n 'robert',\n 'wish',\n 'running',\n 'hero',\n 'body',\n 'somewhat',\n 'major',\n 'ridiculous',\n 'view',\n 'saying',\n '4',\n 'taking',\n 'female',\n 'events',\n 'power',\n 'knew',\n 'level',\n 'happy',\n 'call',\n 'directors',\n 'strange',\n 'knows',\n 'talking',\n 'room',\n '5',\n 'king',\n 'attention',\n 'turned',\n 'future',\n 'supporting',\n 'documentary',\n 'apparently',\n 'sequence',\n 'novel',\n 'basically',\n 'arent',\n 'talent',\n 'songs',\n 'rating',\n 'clearly',\n 'husband',\n 'easily',\n 'due',\n 'country',\n 'words',\n 'local',\n 'tells',\n 'disappointed',\n 'appears',\n 'modern',\n 'british',\n 'problems',\n 'viewers',\n 'falls',\n 'sets',\n 'four',\n 'whether',\n 'important',\n 'bring',\n 'cheap',\n 'predictable',\n 'beyond',\n 'word',\n 'whats',\n 'silly',\n 'review',\n 'television',\n 'single',\n 'light',\n 'earth',\n 'needs',\n 'miss',\n 'similar',\n 'comic',\n 'entertainment',\n 'add',\n 'romantic',\n 'giving',\n 'enjoyable',\n 'five',\n 'jack',\n 'storyline',\n 'sequel',\n 'animation',\n 'actual',\n 'within',\n 'havent',\n 'begins',\n 'mention',\n 'upon',\n 'talk',\n 'herself',\n 'george',\n 'lots',\n 'bunch',\n 'lady',\n 'feels',\n 'ways',\n 'nearly',\n 'moving',\n 'surprised',\n 'using',\n 'points',\n 'paul',\n 'message',\n 'above',\n 'dull',\n 'theme',\n 'sorry',\n 'named',\n 'dialog',\n 'rock',\n 'thriller',\n 'comments',\n 'ten',\n 'team',\n 'richard',\n 'showing',\n 'theater',\n 'stay',\n 'mystery',\n 'effort',\n 'avoid',\n 'fantastic',\n 'middle',\n 'typical',\n 'somehow',\n 'parents',\n 'release',\n 'doubt',\n 'york',\n 'writer',\n 'fall',\n 'easy',\n 'leads',\n 'tried',\n 'viewing',\n 'general',\n 'tale',\n 'soundtrack',\n 'certain',\n 'sister',\n 'near',\n 'kept',\n 'hate',\n 'elements',\n 'among',\n 'weak',\n 'eye',\n 'means',\n 'filmed',\n 'working',\n 'feature',\n 'famous',\n 'class',\n 'check',\n 'learn',\n 'clear',\n 'editing',\n 'realistic',\n 'gone',\n 'figure',\n 'fast',\n 'particular',\n 'material',\n 'straight',\n 'sequences',\n 'form',\n 'follow',\n 'season',\n 'dance',\n 'brought',\n 'imagine',\n 'greatest',\n 'buy',\n 'eventually',\n 'period',\n 'hear',\n 'french',\n 'de',\n 'zombie',\n 'red',\n 'oscar',\n 'reviews',\n 'move',\n 'atmosphere',\n 'lame',\n 'forget',\n 'youve',\n 'die',\n 'space',\n 'deal',\n 'tom',\n 'expected',\n 'whos',\n 'whatever',\n 'okay',\n 'decided',\n 'truth',\n 'wait',\n 'surprise',\n 'indeed',\n 'believable',\n 'became',\n 'third',\n 'stand',\n 'sit',\n 'nature',\n 'poorly',\n 'peter',\n 'difficult',\n 'meets',\n 'possibly',\n 'note',\n 'lee',\n 'subject',\n 'premise',\n 'suspense',\n 'killing',\n 'writers',\n 'screenplay',\n 'leaves',\n 'romance',\n 'filmmakers',\n 'crime',\n 'nor',\n 'memorable',\n 'superb',\n 'stage',\n 'japanese',\n 'average',\n 'question',\n 'reading',\n 'rent',\n 'needed',\n '80s',\n 'sexual',\n 'write',\n 'street',\n 'begin',\n 'interested',\n 'situation',\n 'meet',\n 'keeps',\n 'dr',\n 'older',\n 'dramatic',\n 'society',\n 'boys',\n 'forced',\n 'footage',\n 'earlier',\n 'otherwise',\n 'unless',\n 'minute',\n 'result',\n 'emotional',\n 'badly',\n 'disney',\n 'features',\n 'credits',\n 'whom',\n 'shame',\n 'realize',\n 'previous',\n 'joe',\n 'comment',\n 'baby',\n 'total',\n 'effect',\n 'development',\n 'crazy',\n 'hands',\n 'mess',\n 'personal',\n 'weird',\n 'laughs',\n 'towards',\n 'imdb',\n 'directing',\n 'beauty',\n 'twist',\n 'incredibly',\n 'hot',\n 'sounds',\n 'male',\n 'brings',\n 'ask',\n 'appear',\n 'dog',\n 'background',\n 'apart',\n 'cheesy',\n 'america',\n 'creepy',\n 'b',\n 'remake',\n 'secret',\n 'return',\n 'quickly',\n 'perfectly',\n 'unique',\n 'portrayed',\n 'plenty',\n 'open',\n 'leading',\n 'fairly',\n 'scifi',\n 'plus',\n 'mark',\n 'ideas',\n '70s',\n 'meant',\n 'deep',\n 'worked',\n 'hardly',\n 'admit',\n 'free',\n '20',\n 'powerful',\n 'christmas',\n 'gay',\n 'forward',\n 'dream',\n 'casting',\n 'missing',\n 'setting',\n 'fantasy',\n 'fire',\n 'business',\n 'reasons',\n 'masterpiece',\n 'la',\n 'fails',\n 'create',\n 'attempts',\n 'unlike',\n 'joke',\n 'inside',\n 'break',\n 'present',\n 'potential',\n 'nudity',\n 'expecting',\n 'dumb',\n 'various',\n 'battle',\n 'rich',\n 'brothers',\n 'outside',\n 'success',\n 'recently',\n 'western',\n 'fighting',\n 'pay',\n 'spoilers',\n 'political',\n ...]"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = vectorize_layer.get_vocabulary()\n",
    "vocab"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "# 将参数写入磁盘 生成tsv文件 可以可以到http://projector.tensorflow.org/进行可视化\n",
    "out_v = io.open('tensorflow_study/tensorflow-text/model_dir/vectors.tsv', 'w', encoding='utf-8')\n",
    "out_m = io.open('tensorflow_study/tensorflow-text/model_dir/metadata.tsv', 'w', encoding='utf-8')\n",
    "\n",
    "for index, word in enumerate(vocab):\n",
    "  if index == 0:\n",
    "    continue  # skip 0, it's padding.\n",
    "  vec = weights[index]\n",
    "  out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
    "  out_m.write(word + \"\\n\")\n",
    "out_v.close()\n",
    "out_m.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}